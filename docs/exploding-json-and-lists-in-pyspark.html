<!DOCTYPE html>
<html lang="en">

<head>
  <title>gross.systems - Exploding JSON and Lists in Pyspark</title>
  <meta charset="utf-8" />
  <meta name="generator" content="Pelican" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="theme/css/main.css" />





</head>

<body>
  <!-- <header>
    <nav>
      <ul>
      </ul>
    </nav>
  </header> -->
  <main>
<article>
  <header>
    <h1>
      <a href="/exploding-json-and-lists-in-pyspark.html" rel="bookmark" title="Permalink to Exploding JSON and Lists in Pyspark">Exploding JSON and Lists in Pyspark</a>
    </h1>
    
  </header>
  <p>JSON can kind of suck in PySpark sometimes. It is often that I end up with a dataframe where the response from an API call or other request is stuffed into a column as a JSON string. It will have a consistent structure but it was either not known or consistent enough ahead of time to be worth expanding before adding it to the dataframe.  The problem I run in to is: <em>How do I dynamically make that JSON into columns and rows?</em></p>
<p>Usually the process involves manually looking at the JSON, figuring out what columns I care about, and then hacking some code to parse the JSON and extract what I need. Its pretty boring and repetitive. It is especially painful when the JSON has a large number of fields you want to extract. Too much typing and too easy to make mistakes. The final straw is when you have lists in the JSON that you want to expose as separate rows.  </p>
<p>To (hopefully) deal with this once more for all time, I have made some generic helper functions to parse JSON in a few formats. For background, this code was developed with the help of, but not exclusively by GPT-4o.</p>
<h2>Finding our schema</h2>
<p>Pyspark has some more niche functions you can use, and some weirdness around how it likes things defined. Our first trick is to combine <code>F.schema_of_json</code> with filtering for the first non null value to identify our JSON schema. Obviously, this means that if our JSON schema is not consistent between rows, things will go sideways.  Once we have the schema, we can use it to populate a new column with the parsed JSON.</p>
<div class="highlight"><pre><span></span><code>schema_df = df.withColumn(
    &quot;struct_schema&quot;, F.schema_of_json(F.col(json_string_column))
).select(&quot;struct_schema&quot;)

schema = schema_df.filter(F.col(&quot;struct_schema&quot;).isNotNull()).first()[
    &quot;struct_schema&quot;
]
df = df.withColumn(column, F.from_json(F.col(json_string_column), schema=schema))
</code></pre></div>

<h2>Exploding JSON</h2>
<p>Next up, we need to take all of our top level JSON keys and make them in to columns.  This is pretty simple, with just needing to know that certain functions and classes exist to be called. The full code has additional error handling and deals with the map type, but since that uses RDDs I suspect it wouldn't work in production anyways.</p>
<div class="highlight"><pre><span></span><code><span class="k">schema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="k">schema</span><span class="o">[</span><span class="n">parsed_json_column</span><span class="o">]</span><span class="p">.</span><span class="n">dataType</span>

<span class="k">for</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">schema</span><span class="p">.</span><span class="nl">fields</span><span class="p">:</span>
<span class="w">    </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">field</span><span class="p">.</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;{parsed_json_column}.{field.name}&quot;</span><span class="p">))</span>
</code></pre></div>

<h2>Pesky List Items</h2>
<p>The real kicker in a lot of these situations is nested data. It is nice to explode the JSON as columns but things get a bit more painful when we have variable length lists of data that can be inside JSON keys. These can be accessed directly via <code>foo.bar[1]</code> but since they have variable length it is really painful to do aggregations across them without hacks like exploding exactly 10 rows and filling gaps with nulls.  To get around this, we can explode the lists into individual rows.  We can do this for multiple columns, although it definitely gets a bit messy if there are lots of relevant columns. In addition, we want to make sure we retain ordering indexes to make it simpler to select only a single row from each record when aggregating outside of the exploded items.</p>
<p>There are two functions below to handle these cases. One for when there are multiple list columns that have corresponding data, so we can zip them together and provide a unified index. Another for when we have a list column where each element is a map, and we want to expand those items out as additional columns with a special prefix. Neither approach is perfect, and this code won't handle all edge cases, but it is a starting point.</p>
<h1>Full Code</h1>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">ArrayType</span>

<span class="c1">## Shared Functions</span>

<span class="k">def</span> <span class="nf">map_json_column</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes a column of JSON strings and remaps them to a Map type by</span>
<span class="sd">    inferring the schema from the first row.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">raw_column</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">_raw&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="n">column</span><span class="p">,</span> <span class="n">raw_column</span><span class="p">)</span>
    <span class="n">schema_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
        <span class="s2">&quot;struct_schema&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">schema_of_json</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">raw_column</span><span class="p">))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;struct_schema&quot;</span><span class="p">)</span>

    <span class="n">schema</span> <span class="o">=</span> <span class="n">schema_df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;struct_schema&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">isNotNull</span><span class="p">())</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span>
        <span class="s2">&quot;struct_schema&quot;</span>
    <span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">column</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">from_json</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">raw_column</span><span class="p">),</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">drop</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">raw_column</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="k">def</span> <span class="nf">extract_json_keys_as_columns</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">json_column</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts each top-level key from a parsed JSON column and creates separate columns for each key.</span>

<span class="sd">    :param df: Input PySpark DataFrame</span>
<span class="sd">    :param json_column: Name of the column containing parsed JSON (as MapType or StructType)</span>
<span class="sd">    :return: DataFrame with top-level keys extracted as individual columns</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get schema of the parsed JSON column</span>
    <span class="n">schema</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">schema</span><span class="p">[</span><span class="n">json_column</span><span class="p">]</span><span class="o">.</span><span class="n">dataType</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span> <span class="p">(</span><span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">StructType</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">MapType</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">json_column</span><span class="si">}</span><span class="s2">&#39; must be of StructType or MapType.&quot;</span><span class="p">)</span>

    <span class="c1"># Extract top-level keys as new columns</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">StructType</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">json_column</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">MapType</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">map_keys</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">json_column</span><span class="p">)))</span>
            <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
            <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">json_column</span><span class="si">}</span><span class="s2">[</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="c1">## Multi Line Item Column Functions</span>

<span class="k">def</span> <span class="nf">explode_all_list_columns</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Explodes all columns in the DataFrame that are lists (ArrayType) into rows,</span>
<span class="sd">    ensuring they are exploded together. Adds an &#39;index&#39; column representing the</span>
<span class="sd">    array index of the exploded value.</span>

<span class="sd">    ...</span>
<span class="sd">    &quot;items&quot;: [1, 2, 3],</span>
<span class="sd">    &quot;cost&quot;: [a, b, c],</span>
<span class="sd">    ...</span>

<span class="sd">    :param df: Input PySpark DataFrame</span>
<span class="sd">    :return: DataFrame with exploded rows and an &#39;index&#39; column</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">list_columns</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">field</span><span class="o">.</span><span class="n">name</span>
        <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">dataType</span><span class="p">,</span> <span class="n">ArrayType</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">list_columns</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No columns with ArrayType found in the DataFrame.&quot;</span><span class="p">)</span>

    <span class="n">temp_col</span> <span class="o">=</span> <span class="s2">&quot;temp_struct&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">temp_col</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">list_columns</span><span class="p">]))</span>

    <span class="c1"># Use select with posexplode to extract both index and values</span>
    <span class="n">exploded_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
        <span class="o">*</span><span class="p">[</span>
            <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">temp_col</span>
        <span class="p">],</span>
        <span class="n">F</span><span class="o">.</span><span class="n">posexplode_outer</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">temp_col</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> <span class="s2">&quot;temp_struct_exploded&quot;</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">list_columns</span><span class="p">:</span>
        <span class="n">exploded_df</span> <span class="o">=</span> <span class="n">exploded_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;temp_struct_exploded.</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">exploded_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;temp_struct&quot;</span><span class="p">,</span> <span class="s2">&quot;temp_struct_exploded&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">clean_dataframe_with_separate_line_item_lists</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">raw_response_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;raw_response&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cleans up the invoice DataFrame by:</span>
<span class="sd">    1. Parsing the JSON column</span>
<span class="sd">    2. Extracting top-level keys as separate columns</span>
<span class="sd">    3. Exploding list columns into rows</span>

<span class="sd">    :param df: Input PySpark DataFrame</span>
<span class="sd">    :return: Cleaned up DataFrame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">map_json_column</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">raw_response_col</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">extract_json_keys_as_columns</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">raw_response_col</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">explode_all_list_columns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="c1">## Single Line Item Functions</span>

<span class="k">def</span> <span class="nf">explode_array_of_maps</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">array_col</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Explodes an array column containing maps into separate columns.</span>

<span class="sd">    Takes a DataFrame with an array column containing maps and explodes it into separate rows,</span>
<span class="sd">    with each map&#39;s keys becoming new columns. The original array column is replaced with individual </span>
<span class="sd">    columns for each key in the maps, suffixed with the original column name.</span>

<span class="sd">    ...</span>
<span class="sd">    items = [</span>
<span class="sd">        {&quot;cost&quot;: 1.0, &quot;other_cost&quot;: 0.12},</span>
<span class="sd">        {&quot;cost&quot;: 2.0, &quot;other_cost&quot;: 0.13},</span>
<span class="sd">    ]</span>
<span class="sd">    ...</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pyspark.sql.DataFrame): Input DataFrame containing the array column</span>
<span class="sd">        array_col (str): Name of the array column containing maps to explode</span>

<span class="sd">    Returns:</span>
<span class="sd">        pyspark.sql.DataFrame: DataFrame with array column exploded into separate columns and rows,</span>
<span class="sd">            with an additional &#39;index&#39; column indicating the position in the original array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df_exploded</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">posexplode_outer</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">array_col</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> <span class="s2">&quot;map&quot;</span><span class="p">))</span>

    <span class="c1"># Extract the keys dynamically from the schema</span>
    <span class="n">map_schema</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">array_col</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;map&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">schema</span><span class="p">[</span><span class="s2">&quot;map&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataType</span>
    <span class="p">)</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">field</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">map_schema</span><span class="o">.</span><span class="n">fields</span><span class="p">]</span>

    <span class="c1"># Select original columns, map keys, and index as the last field</span>
    <span class="n">original_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">array_col</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">df_exploded</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
        <span class="o">*</span><span class="n">original_cols</span><span class="p">,</span>
        <span class="o">*</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;map.</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">array_col</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">],</span>
        <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">clean_dataframe_with_single_line_item_list</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">line_item_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;line_items&quot;</span><span class="p">,</span>
    <span class="n">raw_response_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;raw_response&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cleans up the invoice DataFrame by:</span>
<span class="sd">    1. Parsing the JSON column</span>
<span class="sd">    2. Extracting top-level keys as separate columns</span>
<span class="sd">    3. Exploding line_item column into rows</span>

<span class="sd">    :param df: Input PySpark DataFrame</span>
<span class="sd">    :return: Cleaned up DataFrame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">map_json_column</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">raw_response_col</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">extract_json_keys_as_columns</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">raw_response_col</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">explode_array_of_maps</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">line_item_col</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div>
  <footer>
    <p>Published: <time datetime="2025-02-28T00:00:00-05:00">
        2025-02-28
      </time></p>
  </footer>
  <!--         <p>
          Category: <a href="/category/misc.html">misc</a>
        </p>
  </footer> -->
</article>
  </main>
</body>

</html>